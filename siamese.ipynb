{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_path = '/content/drive/My Drive/Tongji_Palmprint'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbNNAVBs2GgP",
        "outputId": "f9cc38bc-8c93-4700-b25c-ac7e5b66859b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKoyVNYi4HLn",
        "outputId": "376cb657-e639-4e1c-a235-66f592710049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.14.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "# The shared link to the dataset file\n",
        "url = 'https://drive.google.com/uc?id=15hEsOm0fZKUHpFNChPSjwiRfMczxcnVQ'\n",
        "output = '/content/drive/MyDrive/Tongji_Contactless_Palmprint_Dataset.zip'  # Path in your Google Drive\n",
        "\n",
        "# Download the file\n",
        "gdown.download(url, output, quiet=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "gnJZyFfR4INh",
        "outputId": "96a2137a-679c-4e32-ea33-2430ea43f58a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=15hEsOm0fZKUHpFNChPSjwiRfMczxcnVQ\n",
            "From (redirected): https://drive.google.com/uc?id=15hEsOm0fZKUHpFNChPSjwiRfMczxcnVQ&confirm=t&uuid=86e174bd-f919-4595-927e-ecc4f73d3e7e\n",
            "To: /content/drive/MyDrive/Tongji_Contactless_Palmprint_Dataset.zip\n",
            "100%|██████████| 4.95G/4.95G [01:02<00:00, 79.6MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Tongji_Contactless_Palmprint_Dataset.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the path to the zip file\n",
        "zip_file_path = '/content/Tongji_Contactless_Palmprint_Dataset.zip'\n",
        "extract_dir = '/content/extracted_files'\n",
        "\n",
        "# Function to extract files\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "  # List all files in the zip file\n",
        "  file_list = zip_ref.namelist()\n",
        "  print(\"Files in the zip file:\", file_list)\n",
        "\n",
        "  # Try to extract all files\n",
        "  zip_ref.extractall(extract_dir)\n",
        "  print(f\"Files have been extracted to {extract_dir}\")\n",
        "\n",
        "\n",
        "\n",
        "# Extract the zip file\n",
        "extract_zip(zip_file_path, extract_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "Exad1qxk8i8g",
        "outputId": "118fa215-6dcf-4593-c3b8-c92e5e312839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Tongji_Contactless_Palmprint_Dataset.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a8ac60763e47>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Function to extract files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0;31m# List all files in the zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Tongji_Contactless_Palmprint_Dataset.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "0sxfYGINx3DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the Siamese Network\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.cnn = models.vgg16(pretrained=True).features\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 256)\n",
        "        )\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = x.view(x.size()[0], -1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        output1 = self.forward_once(input1)\n",
        "        output2 = self.forward_once(input2)\n",
        "        return output1, output2\n",
        "\n",
        "# Define the Contrastive Loss\n",
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, margin=2.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "        loss = torch.mean((1 - label) * torch.pow(euclidean_distance, 2) +\n",
        "                          label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "        return loss\n",
        "\n",
        "# Custom Dataset for Siamese Network\n",
        "class SiameseDataset(Dataset):\n",
        "    def __init__(self, imageFolderDataset, transform=None):\n",
        "        self.imageFolderDataset = imageFolderDataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "        # Ensure the second image is of the same class or different class based on label\n",
        "        should_get_same_class = random.randint(0, 1)\n",
        "        if should_get_same_class:\n",
        "            while True:\n",
        "                img1_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "                if img0_tuple[1] == img1_tuple[1]:\n",
        "                    break\n",
        "        else:\n",
        "            while True:\n",
        "                img1_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "                if img0_tuple[1] != img1_tuple[1]:\n",
        "                    break\n",
        "\n",
        "        img0 = Image.open(img0_tuple[0])\n",
        "        img1 = Image.open(img1_tuple[0])\n",
        "        img0 = img0.convert(\"RGB\")\n",
        "        img1 = img1.convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "\n",
        "        return img0, img1, torch.from_numpy(np.array([int(img0_tuple[1] != img1_tuple[1])], dtype=np.float32))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imageFolderDataset.imgs)"
      ],
      "metadata": {
        "id": "BliynTIryAP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training process\n",
        "def train_siamese_network(train_dataloader, num_epochs=20, learning_rate=0.0001):\n",
        "    model = SiameseNetwork().to(device)\n",
        "    criterion = ContrastiveLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, data in enumerate(train_dataloader, 0):\n",
        "            img0, img1, label = data\n",
        "            img0, img1, label = img0.to(device), img1.to(device), label.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output1, output2 = model(img0, img1)\n",
        "            loss_contrastive = criterion(output1, output2, label)\n",
        "            loss_contrastive.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Epoch number {epoch+1}/{num_epochs}, Current loss {loss_contrastive.item():.4f}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "mmQZlkFcyE3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations and dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "U-dcHUNByJPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_dataset = torchvision.datasets.ImageFolder(root=\"data/training\")\n",
        "siamese_dataset = SiameseDataset(imageFolderDataset=folder_dataset, transform=transform)\n",
        "train_dataloader = DataLoader(siamese_dataset, shuffle=True, num_workers=8, batch_size=32)\n",
        "\n",
        "# Train the Siamese Network\n",
        "siamese_model = train_siamese_network(train_dataloader)\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(siamese_model.state_dict(), 'siamese_network.pt')\n",
        "\n",
        "# Function to visualize some sample pairs\n",
        "def show_plot(iteration, loss):\n",
        "    plt.plot(iteration, loss)\n",
        "    plt.show()\n",
        "\n",
        "siamese_model = train_siamese_network(train_dataloader)\n",
        "torch.save(siamese_model.state_dict(), 'siamese_network.pt')"
      ],
      "metadata": {
        "id": "8RnHeUlkyN5N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}